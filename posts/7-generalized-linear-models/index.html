<!DOCTYPE html>
<html lang='en' ><meta charset="utf-8">
<meta name="viewport" content="width=device-width">


<title>Generalized Linear Models | ME</title>
<link rel="stylesheet" href="/css/eureka.min.css">
<script defer src="/js/eureka.min.js"></script>

<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
  href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600;700&family=Noto+Serif+SC:wght@400;600;700&display=swap"
  as="style" onload="this.onload=null;this.rel='stylesheet'">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/styles/solarized-light.min.css%25!%28EXTRA%20string=solarized-light%29"
   media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/highlight.min.js"
   crossorigin></script>

  <script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/languages/dart.min.js"
     crossorigin></script>

<script defer src="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/js/all.min.js"
   integrity="sha256-uNYoXefWRqv&#43;PsIF/OflNmwtKM4lStn9yrz2gVl6ymo="  crossorigin></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
   integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3&#43;Aro6EYUG4&#43;cU&#43;KJWu/X"  media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" 
  integrity="sha384-g7c&#43;Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI&#43;sEnkvrMWph2EDg4"  crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
   integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC&#43;Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa"  crossorigin></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\\(", right: "\\)", display: false },
        { left: "\\[", right: "\\]", display: true }
      ],
    });
  });
</script>


<link rel="icon" type="image/png" sizes="32x32" href="/images/icon_hu64421c6c7700f606f0ad45d807017b09_5843_32x32_fill_box_center_2.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/icon_hu64421c6c7700f606f0ad45d807017b09_5843_180x180_fill_box_center_2.png">

<meta name="description"
  content="In my previous posts I have talked about linear and logistic regression. Today I will talk about the broader family of models to which both methods belong Generalized Linear Models. To work our way up to GLMs, we will begin by defining the exponential family.
The exponential family: A class of distributions is in the exponential family if it can be written in the form:
$$ p(y;\eta) = b(y) \text{exp}(\eta^T T(y) - \alpha(\eta)) $$
 More information can be found here">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
      "@type": "ListItem",
      "position": 1 ,
      "name":"Posts",
      "item":"/posts/"},{
      "@type": "ListItem",
      "position": 2 ,
      "name":"Generalized Linear Models",
      "item":"/posts/7-generalized-linear-models/"}]
}
</script>



<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "/posts/7-generalized-linear-models/"
    },
    "headline": "Generalized Linear Models | ME","datePublished": "2020-02-17T00:00:00+00:00",
    "dateModified": "2020-02-17T00:00:00+00:00",
    "wordCount":  800 ,
    "publisher": {
        "@type": "Person",
        "name": "C. Wang",
        "logo": {
            "@type": "ImageObject",
            "url": "/images/icon.png"
        }
        },
    "description": "In my previous posts I have talked about linear and logistic regression. Today I will talk about the broader family of models to which both methods belong Generalized Linear Models. To work our way up to GLMs, we will begin by defining the exponential family.\nThe exponential family: A class of distributions is in the exponential family if it can be written in the form:\n$$ p(y;\\eta) = b(y) \\text{exp}(\\eta^T T(y) - \\alpha(\\eta)) $$\n More information can be found here"
}
</script><meta property="og:title" content="Generalized Linear Models | ME" />
<meta property="og:type" content="article" />


<meta property="og:image" content="/images/icon.png">


<meta property="og:url" content="/posts/7-generalized-linear-models/" />




<meta property="og:description" content="In my previous posts I have talked about linear and logistic regression. Today I will talk about the broader family of models to which both methods belong Generalized Linear Models. To work our way up to GLMs, we will begin by defining the exponential family.
The exponential family: A class of distributions is in the exponential family if it can be written in the form:
$$ p(y;\eta) = b(y) \text{exp}(\eta^T T(y) - \alpha(\eta)) $$
 More information can be found here" />




<meta property="og:locale" content="en" />




<meta property="og:site_name" content="ME" />






<meta property="article:published_time" content="2020-02-17T00:00:00&#43;00:00" />


<meta property="article:modified_time" content="2020-02-17T00:00:00&#43;00:00" />



<meta property="article:section" content="posts" />




<body class="flex flex-col min-h-screen">
  <header class="fixed flex items-center w-full min-h-16 pl-scrollbar z-50 bg-secondary-bg shadow-sm">
    <div class="w-full max-w-screen-xl mx-auto"><script>
    let storageColorScheme = localStorage.getItem("lightDarkMode")
    if (((storageColorScheme == 'Auto' || storageColorScheme == null) && window.matchMedia("(prefers-color-scheme: dark)").matches) || storageColorScheme == "Dark") {
        document.getElementsByTagName('html')[0].classList.add('dark')
    }
</script>
<nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0">
    <a href="/" class="mr-6 text-primary-text text-xl font-bold">ME</a>
    <button id="navbar-btn" class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
        <i class="fas fa-bars"></i>
    </button>

    <div id="target"
        class="hidden block md:flex md:flex-grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20">
        <div class="md:flex md:h-16 text-sm md:flex-grow pb-4 md:pb-0 border-b md:border-b-0">
            <a href="/#about" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  mr-4">About</a>
            <a href="/posts/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  selected-menu-item  mr-4">Posts</a>
        </div>

        <div class="flex">
            <div class="relative pt-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="lightDarkMode">
                    <i class="fas fa-adjust"></i>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open">
                </div>
                <div class="absolute flex flex-col left-0 md:left-auto right-auto md:right-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='lightDarkOptions'>
                    <span class="px-4 py-1 hover:text-eureka">Light</span>
                    <span class="px-4 py-1 hover:text-eureka">Dark</span>
                    <span class="px-4 py-1 hover:text-eureka">Auto</span>
                </div>
            </div>
        </div>
    </div>

    <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id="is-open-mobile">
    </div>

</nav>
<script>
    let element = document.getElementById('lightDarkMode')
    if (storageColorScheme == null || storageColorScheme == 'Auto') {
        document.addEventListener('DOMContentLoaded', () => {
            switchMode('Auto')
        })
    } else if (storageColorScheme == "Light") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'sun')
        element.firstElementChild.classList.add('fa-sun')
    } else if (storageColorScheme == "Dark") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'moon')
        element.firstElementChild.classList.add('fa-moon')
    }
    
    document.addEventListener('DOMContentLoaded', () => {
        getcolorscheme();
        switchBurger();
    });
</script></div>
  </header>
  <main class="flex-grow pt-16">
    <div class="pl-scrollbar">
      <div class="w-full max-w-screen-xl lg:px-4 xl:px-8 mx-auto">


<div class="grid grid-cols-2 lg:grid-cols-8 gap-4 lg:pt-12">
    <div
        class="col-span-2 lg:col-start-2 lg:col-span-6 bg-secondary-bg rounded px-6 py-8">
        <h1 class="font-bold text-3xl text-primary-text">Generalized Linear Models</h1>
        <div class="flex flex-wrap flex-row items-center mt-2 text-tertiary-text">
    <div class="mr-6 my-2">
        <i class="fas fa-calendar mr-1"></i>
        <span>2020-02-17</span>
    </div>
    <div class="mr-6 my-2">
        <i class="fas fa-clock mr-1"></i>
        <span>4 min read</span>
    </div>
    
    

    
</div>
        
        
        

        <div class="content">
            <p>In my previous posts I have talked about linear and logistic regression. Today I will talk about the broader family of models to which both methods belong <em>Generalized Linear Models</em>. To work our way up to GLMs, we will begin by defining the exponential family.</p>
<p><em><strong>The exponential family:</strong></em> A class of distributions is in the exponential family if it can be written in the form:</p>
<p>$$
p(y;\eta) = b(y) \text{exp}(\eta^T T(y) - \alpha(\eta))
$$</p>
<blockquote>
<p>More information can be found here</p>
</blockquote>
<h4 id="linear-regression-as-a-glm">Linear regression as a GLM</h4>
<p>Maybe you remember that the underlying assumption used in the least squares cost function of linear regression was that, the conditional distribution of $y$ given $x$ is defined by a gaussian (normal) distribution. It turns out a gaussian distribution is part of the exponential family and can be written as follows:</p>
<div>
\[\begin{aligned}
    p(y;\mu) =& \dfrac{1}{\sqrt{2\pi}} \text{exp} \left( -\dfrac{1}{2} (y-\mu)^2 \right) \\
    =& \dfrac{1}{\sqrt{2\pi}} \text{exp} \left( -\dfrac{1}{2}y^2 \right) \cdot \text{exp} \left( \mu y - \dfrac{1}{2} \mu^2 \right) \\
    \\
    \eta =& \mu \\
    T(y) =& y \\
    a(\eta) =& \dfrac{\mu^2}{2} \\
    =& \dfrac{\eta^2}{2} \\
    b(y) =& \dfrac{1}{\sqrt{2\pi}} \text{exp}(\dfrac{y^2}{2})
\end{aligned}\]
</div>
<blockquote>
<p>Note that standard deviation $\sigma$ has been set to 1. This is done because it makes the derivation easier and since it is of no influence on our final choice of $\theta$ we are allowed to choose it arbitrarily.</p>
</blockquote>
<p>One of the assumptions made when constructing a GLM is that the natural parameter $\eta$ and the inputs $x$ are related linearly: $\eta = \theta^T x$. Which brings us back to final form the hypothesis function of the linear regression algorithm. To formulate the hypothesis function of a GLM we equate it to the expected value of the conditional distribution:</p>
<div>
\[\begin{aligned}
	h_{\theta}(x) =& E[y|\eta] = E[y|x;\theta] \\
	=& \mu \\
	=& \eta \\
	=& \theta^T x \\
\end{aligned}\]
</div>
<h4 id="logistic-regression-as-a-glm">Logistic regression as a GLM</h4>
<p>The same procedure can be used to derive the logistic regression classifier as a GLM. The classifier assumes a bernoulli conditional distribution of $y$ given $x$. Rewriting the bernoulli distribution as part of the exponential family gives:</p>
<div>
\[\begin{aligned}
    p(y;\phi) =& \phi^y (1-\phi)^{1-y} \\
    =& \text{exp} (y \text{log} \phi + (1-y) \text{log}(1-\phi)) \\
    =& \text{exp} \left( \left( \text{log} \left( \dfrac{\phi}{1-\phi} \right) \right) y + \text{log}(1-\phi) \right) \\ \newline
    \eta &= \text{log} (\dfrac{\phi}{1-\phi}) \\
    T(y) &= y \\
    a(\eta) &= -\text{log}(1-\phi) \\
    &= -\text{log}(1- e^{\eta}) \\
    b(y) &= 1
\end{aligned}\]
</div>
<p>Again to formulate the hypothesis function of the logistic regression classifier we equate to the expected value of the conditional distribution:</p>
<div>
\[\begin{aligned}
    h_{\theta}(x) =& E[y|\eta] = E[y|x;\theta] \\
    &= \phi \\
    &= \dfrac{1}{1+e^{-\eta}} \\
    &= \dfrac{1}{1+e^{-\theta^T x}} \\
\end{aligned}\]
</div>
<h4 id="softmax-regression">Softmax regression</h4>
<p>An example of a GLM that I have not mentioned before in other posts is the softmax regression algorithm. This class of GLM that assumes a multinomial conditional distribution of $y$ given $x$. This type of distribution is appropriate for classification with more than two classes.</p>
<p>To derive the hypothesis function for the softmax algorithm we will start by expressing the multinomial as an exponential family distribution. Up until now we have only seen $T(y) = y$, however for the multinomial distribution the <strong>sufficient statistic</strong> $T(y)$ is actually a vector of size equal to the number of classes:</p>
<div>
\[\begin{aligned}
    p(y;\phi) =& \phi^{1\{y=1\}}_1 \phi^{1\{y=2\}}_2 ... \phi^{1\{y=k\}}_k \\
    =& \phi^{1\{y=1\}}_1 \phi^{1\{y=2\}}_2 ... \phi^{1 - \Sigma^{k-1}_{i=1}1\{y=i\}}_k \\
    =& \phi^{(T(y))_1}_1 \phi^{(T(y))_2}_2 ... \phi^{1 - \Sigma^{k-1}_{i=1}(T(y))_i}_k \\
    =& \text{exp} ((T(y))_1 \text{log}(\phi_1) + (T(y))_2 \text{log}(\phi_2) + ... + (1-\Sigma^{k-1}_{i=1} (T(y))_i)\text{log}(\phi_k)) \\
    =& \text{exp} ((T(y))_1 \text{log}(\dfrac{\phi_1}{\phi_k}) + (T(y))_2 \text{log}(\dfrac{\phi_2}{\phi_k}) + ... + (T(y))_{k-1}\text{log}(\dfrac{\phi_{k-1}}{\phi_k}) + \text{log}(\phi_k)) \\
\end{aligned}\]
</div>
<div>
\[\begin{aligned}
    \eta =&
        \begin{bmatrix}
            \log(\dfrac{\phi_1}{\phi_k}) \\
            \log(\dfrac{\phi_2}{\phi_k}) \\
            \vdots \\
            \log(\dfrac{\phi_{k-1}}{\phi_k})
        \end{bmatrix} \\
    a(\eta) =& -\log(\phi_k) \\
    b(y) =& 1
\end{aligned}\]
</div>
<blockquote>
<p>Here the notation 1{$\cdot$} takes on a value of 1 if its argument is true, and 0 otherwise. Also $(T(y))_i$ denotes the $i-$th element of the vector $T(y)$.</p>
</blockquote>
<p>Because $T(y)$ is a vector the hypothesis function will also be a vector which contains a hypothesis for every class. The expectation of a single class in obtained from the natural parameter as follows:</p>
<div>
\[\begin{aligned}
	\eta_i =& \log \dfrac{\phi_i}{\phi} \\
	e^{\eta_i} =& \dfrac{\phi_i}{\phi} \\
	\phi_k e^{\eta_i} =& \phi_i \\
	\\
	\phi_k \Sigma^k_{i=1} e^{\eta_i} =& \Sigma^k_{i=1} \phi_i = 1 \\
	\\
	\phi_i =& \dfrac{e^{\eta_i}}{\Sigma^k_{j=1} e^{\eta_j}}
\end{aligned}\]
</div>
<p>Finally The entire hypothesis function will look as follows:</p>
<div>
\[\begin{aligned}
    h_{\theta}(x) =& E[T(y)|x;\theta] \\
    =&
    \begin{bmatrix}
        \dfrac{e^{\theta^T_1 x}}{\Sigma^k_{j=1} e^{\theta^T_j x}} \\
        \dfrac{e^{\theta^T_2 x}}{\Sigma^k_{j=1} e^{\theta^T_j x}} \\
        \vdots \\
        \dfrac{e^{\theta^T_{k-1} x}}{\Sigma^k_{j=1} e^{\theta^T_j x}} \\
    \end{bmatrix}
\end{aligned}\]
</div>
<blockquote>
<p>Note that to use the softmax algorithm as a classifier all you have to do is output the class for which the hypothesis is highest.</p>
</blockquote>
<p>We have not talked about the cost function and the update rule to actually train this classifier. The appropriate update rule can be derived using maximum likelihood estimation. I will not go into detail about this here.</p>
<blockquote>
<p>See &hellip; for more details.</p>
</blockquote>

        </div>
        
        
        
        
        
        
        
<div class="flex flex-col md:flex-row md:justify-between -mx-2 mt-4 px-2 pt-4 border-t">
    <div>
        
        <span class="block font-bold">Previous</span>
        <a href="/posts/9-robot-experiment/" class="block">Formula student driverless</a>
        
    </div>
    <div class="md:text-right mt-4 md:mt-0">
        
        <span class="block font-bold">Next</span>
        <a href="/posts/6-logistic-regression/" class="block">Logistic Regression</a>
        
    </div>
</div>

        
    </div>
    

    
    
</div>
<script>
    document.addEventListener('DOMContentLoaded', ()=>{
        hljs.initHighlightingOnLoad();
    })
</script>

      </div>
    </div>
    
  </main>
  <footer class="pl-scrollbar">
    <div class="w-full max-w-screen-xl mx-auto"><div class="text-center p-6 pin-b">
    <p class="text-sm text-tertiary-text">&copy; 2021 <a href="https://www.wangchucheng.com/">C. Wang</a> and <a href="https://www.ruiqima.com/">R. Ma</a>
 &middot;  Powered by the <a href="https://github.com/wangchucheng/hugo-eureka" class="hover:text-eureka">Eureka</a> theme for <a href="https://gohugo.io" class="hover:text-eureka">Hugo</a></p>
</div></div>
  </footer>
</body>

</html>